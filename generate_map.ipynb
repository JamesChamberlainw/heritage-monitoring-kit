{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55fa7315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import fiona\n",
    "import geemap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Gee and EE \n",
    "import ee\n",
    "\n",
    "# Clustering (best for testing** due to speed)\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# tif file creation\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "# Plotting and Vis \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6937ae28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialise\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=\"jameswilliamchamberlain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6c51023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# basemap \n",
    "basemap_url = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}'\n",
    "\n",
    "# centeral point of Samarra \n",
    "df_sites = pd.DataFrame({\n",
    "    \"longitude\": [43.823543],\n",
    "    \"latitude\": [34.340989],\n",
    "    \"name\": [\"Samarra Archaeological City\"],\n",
    "    \"category\": [\"Cultural\"],\n",
    "    \"date inscribed\": [\"2007\"],\n",
    "    \"region\": [\"Arab States\"],\n",
    "    \"url\": [\"https://whc.unesco.org/en/list/276\"],\n",
    "    \"iso\": [[\"IQ\"]]\n",
    "})\n",
    "\n",
    "# Chunks of Samarra Archaeological City \n",
    "with fiona.open(\"chunks_new.shp\") as src:\n",
    "    chunks = gpd.GeoDataFrame.from_features(src, crs=src.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65ec00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8732864f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TEMP REMOVE ADDITIONAL STUFF FOR QUICKER TESTING \n",
    "# tile_43641125_34108721_43915744_34336837 only \n",
    "\n",
    "chunks = chunks[chunks['file_name'] == 'tile_43641125_34108721_43915744_34336837']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a2d815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79b661b918b460e913d5e44fe04c57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[34.340989, 43.823543], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=Sear…"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = geemap.Map()\n",
    "\n",
    "if df_sites.empty:\n",
    "    print(\"No sites found for the specified URL.\")\n",
    "else:\n",
    "    m.add_points_from_xy(df_sites, x=\"longitude\", y=\"latitude\", layer_name=\"Sites\")\n",
    "    center_points = df_sites[['longitude', 'latitude']].mean().values\n",
    "    m.setCenter(center_points[0], center_points[1], 10)\n",
    "\n",
    "m.add_basemap(basemap_url, name=\"Google Satellite\", attribution=\"Google\")\n",
    "\n",
    "# add chunks from aoi \n",
    "m.add_gdf(chunks, layer_name=\"AOI\", style={\"color\": \"red\", \"fillColor\": \"red\", \"fillOpacity\": 0.1})\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13096b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_subregions(chunks, sift_percentage_lon=0.5, sift_percentage_lat=0.415):\n",
    "    \"\"\"\n",
    "        Shifts all polygons to 8 positions based on half the length in longitude and latitude, to create subregions - one for each direction from the center.\n",
    "\n",
    "        Assumes aoi contains all similar polygons, and are similar to a square.\n",
    "\n",
    "        Parameters:\n",
    "            aoi (GeoDataFrame): The area of interest containing geometries.\n",
    "            sift_percentage (float): Percentage of the length to shift the center point. Default is 0.5 (50%) for half the length.\n",
    "    \"\"\"\n",
    "\n",
    "    if chunks.empty:\n",
    "        return {}\n",
    "    \n",
    "    first_polygon = chunks.geometry.iloc[0]\n",
    "\n",
    "    # take top two points of the polygon and get the length between them\n",
    "    top_points = first_polygon.exterior.coords[:2]\n",
    "    length_lon = abs(top_points[0][0] - top_points[1][0])\n",
    "\n",
    "    # calculate the shift amount\n",
    "    shift_amount_lon = length_lon * sift_percentage_lon \n",
    "    shift_amount_lat = length_lon * sift_percentage_lat\n",
    "\n",
    "    shift_directions = {\n",
    "        \"left\": (-shift_amount_lon, 0),\n",
    "        \"right\": (shift_amount_lon, 0),\n",
    "        \"up\": (0, shift_amount_lat),\n",
    "        \"down\": (0, -shift_amount_lat),\n",
    "        \"top_left\": (-shift_amount_lon, shift_amount_lat),\n",
    "        \"top_right\": (shift_amount_lon, shift_amount_lat),\n",
    "        \"bottom_left\": (-shift_amount_lon, -shift_amount_lat),\n",
    "        \"bottom_right\": (shift_amount_lon, -shift_amount_lat),\n",
    "    }\n",
    "\n",
    "    # shift_directions = {\n",
    "    #     \"left\": (-shift_amount_lon, 0),\n",
    "    #     \"right\": (shift_amount_lon, 0),\n",
    "    #     \"up\": (0, shift_amount_lon),\n",
    "    #     \"down\": (0, -shift_amount_lon),\n",
    "    #     \"top_left\": (-shift_amount_lon, shift_amount_lon),\n",
    "    #     \"top_right\": (shift_amount_lon, shift_amount_lon),\n",
    "    #     \"bottom_left\": (-shift_amount_lon, -shift_amount_lon),\n",
    "    #     \"bottom_right\": (shift_amount_lon, -shift_amount_lon),\n",
    "    # }\n",
    "\n",
    "    subregions = []\n",
    "        \n",
    "    # Create subregions by shifting the geometries in all directions\n",
    "    for _, (dx, dy) in shift_directions.items():\n",
    "        gdf_shifted = chunks.copy()\n",
    "        gdf_shifted[\"geometry\"] = gdf_shifted[\"geometry\"].translate(dx, dy)\n",
    "        subregions.append(gdf_shifted)\n",
    "\n",
    "    # Combine all into one GeoDataFrame\n",
    "    subregions = pd.concat(subregions, ignore_index=True)\n",
    "    return gpd.GeoDataFrame(subregions, crs=chunks.crs)\n",
    "\n",
    "def clip(chunks, aoi):\n",
    "    \"\"\"\n",
    "        Clips the chunks or subregions to the area of interest (aoi).\n",
    "\n",
    "        Parameters:\n",
    "            chunks (GeoDataFrame):      The chunks or subregions to be clipped.\n",
    "            aoi (GeoDataFrame):         The area of interest (aoi) to clip the chunks against.\n",
    "    \"\"\"\n",
    "\n",
    "    # clip to aoi \n",
    "    if chunks.empty or aoi.empty:\n",
    "        return gpd.GeoDataFrame(columns=chunks.columns.tolist(), crs=chunks.crs)\n",
    "    clipped = gpd.clip(chunks, aoi)\n",
    "    clipped = clipped[clipped.geometry.notnull()]  # Remove any null geometries\n",
    "\n",
    "    return clipped.reset_index(drop=True)\n",
    "\n",
    "subregions = create_subregions(chunks)\n",
    "subregions = clip(subregions, aoi=chunks.dissolve())\n",
    "\n",
    "# plot as one \n",
    "m.add_gdf(subregions, layer_name=\"Subregions\", style={\"color\": \"blue\", \"fillColor\": \"blue\", \"fillOpacity\": 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721056f",
   "metadata": {},
   "source": [
    "# Reference Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7d2ba52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def collect_points_from_geemap(map_obj, label):\n",
    "    \"\"\"\n",
    "    Collect all drawn point features from a geemap.Map that uses ee.Feature objects,\n",
    "    and return them as a GeoDataFrame with a label.\n",
    "\n",
    "    Parameters:\n",
    "        map_obj (geemap.Map): The interactive map.\n",
    "        label (str): Label to assign to all collected points.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: With geometry and 'label' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    features = map_obj.draw_features\n",
    "\n",
    "    if not features:\n",
    "        return gpd.GeoDataFrame(columns=[\"geometry\", \"label\"], geometry=\"geometry\")\n",
    "\n",
    "    points = []\n",
    "    for f in features:\n",
    "        try:\n",
    "            geom = f.geometry()  # call the method\n",
    "            if geom.getInfo()[\"type\"] == \"Point\":\n",
    "                coords = geom.coordinates().getInfo()  # [lon, lat]\n",
    "                points.append(Point(coords))\n",
    "        except Exception as e:\n",
    "            print(\"Skipping feature due to error:\", e)\n",
    "\n",
    "    if not points:\n",
    "        return gpd.GeoDataFrame(columns=[\"geometry\", \"label\"], geometry=\"geometry\")\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(geometry=points)\n",
    "    gdf[\"label\"] = label\n",
    "    gdf.set_crs(\"EPSG:4326\", inplace=True)\n",
    "    return gdf\n",
    "\n",
    "def gen_basemap(basemap_url=None, aoi=gpd.GeoDataFrame(), polygons=None):\n",
    "    \"\"\"\n",
    "        Generates a basemap with the specified URL and adds polygons if provided.\n",
    "\n",
    "        Parameters:\n",
    "            basemap_url (str): The URL of the basemap to be used.\n",
    "            polygons (GeoDataFrame, optional): Polygons to be added to the map. Defaults to None.\n",
    "            aoi (GeoDataFrame): The area of interest to be displayed on the map. (can be a set of polygons or a single polygon)\n",
    "        \n",
    "        Returns:\n",
    "            geemap.Map: A geemap map object with the specified basemap and polygons.\n",
    "    \"\"\"\n",
    "    m = geemap.Map()\n",
    "\n",
    "    if not basemap_url:\n",
    "        basemap_url = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}'\n",
    "        \n",
    "    m.add_basemap(basemap_url, name=\"Google Satellite\", attribution=\"Google\")\n",
    "\n",
    "    # center on aoi\n",
    "    if not aoi.empty:\n",
    "        m.add_gdf(aoi, layer_name=\"AOI\", style={\"color\": \"red\", \"fillColor\": \"red\", \"fillOpacity\": 0.1})\n",
    "        center_points = aoi.geometry.unary_union.centroid.coords[0]\n",
    "        m.setCenter(center_points[0], center_points[1], 10)\n",
    "    \n",
    "    if polygons is not None:\n",
    "        m.add_gdf(polygons, layer_name=\"Polygons\", style={\"color\": \"red\", \"fillColor\": \"red\", \"fillOpacity\": 0.1})\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "879236a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of 3 maps for urban, agricultrual, water and waste\n",
    "urban_map = gen_basemap(basemap_url, aoi=chunks)\n",
    "agricultural_map = gen_basemap(basemap_url, aoi=chunks)\n",
    "water_map = gen_basemap(basemap_url, aoi=chunks)\n",
    "wasteland_map = gen_basemap(basemap_url, aoi=chunks)\n",
    "# wasteland_map = geemap.Map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa3c916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c58357a91246d684456413a11e7448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[34.22277923307027, 43.77843455433748], controls=(WidgetControl(options=['position', 'transparent_b…"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ddb6019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e04df9a0fb4f73bec19250b9bcb9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[34.22277923307027, 43.77843455433748], controls=(WidgetControl(options=['position', 'transparent_b…"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agricultural_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1fa3497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321f93bc533b4196a5bdc31546dc56b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[34.22277923307027, 43.77843455433748], controls=(WidgetControl(options=['position', 'transparent_b…"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# water_map = water_waste_map\n",
    "water_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17cc6e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e261192e634dc79f255f98b01de35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[34.22277923307027, 43.77843455433748], controls=(WidgetControl(options=['position', 'transparent_b…"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wasteland_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09657f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert to labelled points in GeoDataFrame\n",
    "\n",
    "water_points = collect_points_from_geemap(water_map, label=\"Water\")\n",
    "agricultural_points = collect_points_from_geemap(agricultural_map, label=\"Agricultural\")\n",
    "urban_points = collect_points_from_geemap(urban_map, label=\"Urban\")\n",
    "wasteland_map = collect_points_from_geemap(wasteland_map, label=\"Wasteland\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e2fba46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_points_to_csv(points, filename):\n",
    "    points.to_csv(filename, index=False)\n",
    "    print(f\"Points saved to {filename}\")\n",
    "\n",
    "def load_points_from_csv(dir):\n",
    "    try:\n",
    "        points = gpd.read_file(dir)\n",
    "        print(f\"Points loaded from {dir}\")\n",
    "        return points\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading points from {dir}: {e}\")\n",
    "        return gpd.GeoDataFrame(columns=[\"geometry\", \"label\"], geometry=\"geometry\")\n",
    "\n",
    "# save_points_to_csv(water_points, \"test1_water_points.csv\")\n",
    "# save_points_to_csv(agricultural_points, \"test1_agricultural_points.csv\")\n",
    "# save_points_to_csv(urban_points, \"test1_urban_points.csv\")\n",
    "# save_points_to_csv(wasteland_map, \"test1_wasteland_points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7edbac9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# merge into one GeoDataFrame\n",
    "points_list = [water_points, agricultural_points, urban_points, wasteland_map]\n",
    "labels = pd.concat(points_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e15ae6",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "Here we create a Sparse matrix\n",
    "\n",
    "then with the sparse matrix compare and label based on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bb927e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 CSV files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/2019.csv']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth = \"data/\"\n",
    "\n",
    "# collect paths for all csv files in the folder\n",
    "paths = []\n",
    "\n",
    "for root, dirs, files in os.walk(pth):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            paths.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"Found {len(paths)} CSV files.\")\n",
    "\n",
    "# select 2024 \n",
    "path = [p for p in paths if \"2019\" in p]\n",
    "path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35a6bd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prep_data(dir):\n",
    "    \"\"\"Creates two dataframes from a CSV file, one ready for clustering with additional columns removed and the other with all columns left intact.\"\"\"\n",
    "    df1 = pd.read_csv(dir)\n",
    "    df1 = df1.dropna()\n",
    "    df2_clear = df1.copy()\n",
    "    df2_clear = df2_clear.drop(columns=[\"system:index\", \".geo\"])\n",
    "    df2_clear = df2_clear.set_index(\"file_name\")\n",
    "    df1 = df1.set_index(\"file_name\")\n",
    "    df2_clear = df2_clear.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    return df1, df2_clear\n",
    "\n",
    "df1, df2_clear = prep_data(path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe0f9de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "class tif_utils:\n",
    "    \"\"\"\n",
    "        A set of utility functions for GeoTIFF files \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # predictions to tif\n",
    "# output_dir = \"/test1_1_predictions.tif\"\n",
    "# export_to_tif(predictions, bands=[\"numeric_label\"], output_dir=output_dir, res=50, UTM_ESPG=32638, EPSG=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b031be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def kmeans_clustering(df, k=10):\n",
    "    \"\"\"sklearn kmeans\"\"\"\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42) # TODO: make random_state random\n",
    "    kmeans.fit(df)\n",
    "    \n",
    "    return kmeans.labels_, df.index.tolist()\n",
    "\n",
    "# def kmeans_clustering(df, **kwargs):\n",
    "#     \"\"\"sklearn kmeans with kwargs example for alternative functions in the future\"\"\"\n",
    "\n",
    "#     import numpy as np\n",
    "#     from sklearn.cluster import KMeans\n",
    "    \n",
    "#     k = kwargs.get('k', 10)\n",
    "#     random_state = kwargs.get('random_state', np.random.randint(0, 1000))\n",
    "\n",
    "#     kmeans = KMeans(n_clusters=k, random_state=random_state) \n",
    "#     kmeans.fit(df)\n",
    "    \n",
    "#     return kmeans.labels_, df.index.tolist()\n",
    "\n",
    "class cluster:\n",
    "    \"\"\"\n",
    "        Takes a set of polygons and a set of points with attached geometry \n",
    "\n",
    "        and runs clustering over all points in the polygons, and returns a set of clusters based on the points.\n",
    "    \"\"\"\n",
    "\n",
    "    df_sparse = pd.DataFrame()\n",
    "\n",
    "    def __init__(self, subregions, df_data, mapping, passes=6, aoi=None, index_column=\"file_name\", points=gpd.GeoDataFrame()):\n",
    "        \"\"\"\n",
    "            Initialises the cluster object with subregions, data, number of subregion passes, the area of interest (aoi), index column, and points.\n",
    "        \"\"\"\n",
    "\n",
    "        # execution variables \n",
    "        self.passes = passes \n",
    "\n",
    "        # Data \n",
    "        self.data = df_data\n",
    "        self.points = points\n",
    "        self.mapping = mapping\n",
    "\n",
    "        # Subregions \n",
    "        if aoi is None:\n",
    "            aoi = subregions.dissolve()\n",
    "\n",
    "        subregions_poly = create_subregions(chunks)\n",
    "        subregions_poly = clip(subregions, aoi=aoi)\n",
    "        self.subregions = subregions_poly\n",
    "\n",
    "        self.index_column = index_column\n",
    "        self.UTM_ESPG = 32638\n",
    "        self.EPSG = 4326\n",
    "\n",
    "        self.gdf_labels = None\n",
    "        self.df_sparse = pd.DataFrame()\n",
    "    \n",
    "    def clip_dataframe(self, polygon, df):\n",
    "        \"\"\"\n",
    "            Clips the DataFrame based on the .geo column and a given polygon.   \n",
    "        \n",
    "        Args:\n",
    "            polygon (shapely.geometry.Polygon): The polygon to clip the DataFrame to.\n",
    "            df (pd.DataFrame): The DataFrame containing the geometries to be clipped.\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: The clipped DataFrame.\n",
    "        \"\"\"\n",
    "\n",
    "        # based on .geo column drop all rows that do not intersect with the polygon\n",
    "        df['geometry'] = df['.geo'].apply(lambda x: shape(json.loads(x)))\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=self.UTM_ESPG)\n",
    "        gdf = gdf[gdf.geometry.within(polygon)]\n",
    "        gdf = gdf.drop(columns=['geometry'])\n",
    "\n",
    "        # convert back to DataFrame\n",
    "        df_clipped = pd.DataFrame(gdf)\n",
    "\n",
    "        return df_clipped\n",
    "    \n",
    "    def clip_polygon(chunks, aoi):\n",
    "        \"\"\"\n",
    "            Clips the chunks or subregions to the area of interest (aoi).\n",
    "\n",
    "            Parameters:\n",
    "                chunks (GeoDataFrame):      The chunks or subregions to be clipped.\n",
    "                aoi (GeoDataFrame):         The area of interest (aoi) to clip the chunks against.\n",
    "        \"\"\"\n",
    "\n",
    "        # clip to aoi \n",
    "        if chunks.empty or aoi.empty:\n",
    "            return gpd.GeoDataFrame(columns=chunks.columns.tolist(), crs=chunks.crs)\n",
    "        clipped = gpd.clip(chunks, aoi)\n",
    "        clipped = clipped[clipped.geometry.notnull()]  # Remove any null geometries\n",
    "\n",
    "        return clipped.reset_index(drop=True)\n",
    "    \n",
    "    def split_df(self, df):\n",
    "        \"\"\"\n",
    "            Creates two dataframes from a CSV file, one ready for clustering with additional columns removed and the other with all columns left intact.\n",
    "        \"\"\"\n",
    "\n",
    "        df1 = df.copy()\n",
    "\n",
    "        df1 = df1.dropna()\n",
    "        df2_clear = df1.copy()\n",
    "        df2_clear = df2_clear.drop(columns=[\"system:index\", \".geo\"])\n",
    "        df2_clear = df2_clear.set_index(\"file_name\")\n",
    "        df1 = df1.set_index(\"file_name\")\n",
    "        df2_clear = df2_clear.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        return df1, df2_clear\n",
    "    \n",
    "    def create_subregions(chunks, sift_percentage=0.5):\n",
    "        \"\"\"\n",
    "            TODO: Replace with updated version above\n",
    "        \"\"\"\n",
    "\n",
    "        if chunks.empty:\n",
    "            return {}\n",
    "        \n",
    "        first_polygon = chunks.geometry.iloc[0]\n",
    "\n",
    "        # take top two points of the polygon and get the length between them\n",
    "        top_points = first_polygon.exterior.coords[:2]\n",
    "        length_lon = abs(top_points[0][0] - top_points[1][0])\n",
    "\n",
    "        # calculate the shift amount\n",
    "        shift_amount = length_lon * sift_percentage\n",
    "\n",
    "        shift_directions = {\n",
    "            \"left\": (-shift_amount, 0),\n",
    "            \"right\": (shift_amount, 0),\n",
    "            \"up\": (0, shift_amount),\n",
    "            \"down\": (0, -shift_amount),\n",
    "            \"top_left\": (-shift_amount, shift_amount),\n",
    "            \"top_right\": (shift_amount, shift_amount),\n",
    "            \"bottom_left\": (-shift_amount, -shift_amount),\n",
    "            \"bottom_right\": (shift_amount, -shift_amount),\n",
    "        }\n",
    "\n",
    "        subregions = []\n",
    "\n",
    "        # Create subregions by shifting the geometries in all directions\n",
    "        for _, (dx, dy) in shift_directions.items():\n",
    "            gdf_shifted = chunks.copy()\n",
    "            gdf_shifted[\"geometry\"] = gdf_shifted[\"geometry\"].translate(dx, dy)\n",
    "            subregions.append(gdf_shifted)\n",
    "\n",
    "        # Combine all into one GeoDataFrame\n",
    "        subregions = pd.concat(subregions, ignore_index=True)\n",
    "        return gpd.GeoDataFrame(subregions, crs=chunks.crs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_df_to_geodf(df, geo_col='.geo', crs=\"EPSG:32638\"):\n",
    "        \"\"\"\n",
    "        Converts a DataFrame with a '.geo' column (GeoJSON strings) to a GeoDataFrame.\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        if df.empty:\n",
    "            return gpd.GeoDataFrame(columns=df.columns.tolist(), crs=crs)\n",
    "        if df is type(gpd.DataFrame):\n",
    "            return df \n",
    "\n",
    "        # Only parse if the entry is a string\n",
    "        def safe_parse(x):\n",
    "            if isinstance(x, str):\n",
    "                try:\n",
    "                    return shape(json.loads(x))\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARNING] Bad geometry skipped: {x[:30]}... ({e})\")\n",
    "            return None\n",
    "\n",
    "        df['geometry'] = df[geo_col].apply(safe_parse)\n",
    "        df = df[df['geometry'].notnull()]  # drop invalid rows\n",
    "\n",
    "        return gpd.GeoDataFrame(df, geometry='geometry', crs=crs)\n",
    "    \n",
    "    \n",
    "    ##################################################################################################################################################################\n",
    "    # ========================================================= BACKUP, RELOADING AND UPDATING DATA ================================================================ #\n",
    "    ##################################################################################################################################################################    \n",
    "\n",
    "    @staticmethod\n",
    "    def save_processed_label_data(geodf, filename):\n",
    "        \"\"\"\n",
    "            Saves the processed GeoDataFrame to a file.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(geodf, gpd.GeoDataFrame):\n",
    "            geodf.to_file(filename, driver='GeoJSON')\n",
    "            print(f\"GeoDataFrame saved to {filename}\")\n",
    "        elif isinstance(geodf, pd.DataFrame):\n",
    "            geodf.to_csv(filename, index=True)\n",
    "            print(f\"DataFrame saved to {filename}\")\n",
    "\n",
    "    def reload(self, dir_data, dir_labels, dir_sparse, dir_points):\n",
    "        \"\"\"\n",
    "            Reloads the data, labels and sparse DataFrame from the specified directories to resume processing.\n",
    "        \"\"\"\n",
    "\n",
    "        # df_test1 = pd.read_csv(\"temp_test/test1_labels.geojson\")\n",
    "        # df_test1 = df_test1.drop(columns=[\"geometry\"]) # does not work for some reason \n",
    "        # df_test1['geometry'] = df_test1['.geo'].apply(lambda x: shape(json.loads(x))) \n",
    "        # gpd_test1 = gpd.GeoDataFrame(df_test1, geometry='geometry', crs=c.UTM_ESPG)\n",
    "\n",
    "        # data\n",
    "        _temp_data = pd.read_csv(dir_data).drop(columns=[\"geometry\"])\n",
    "        _temp_data['geometry'] = _temp_data['.geo'].apply(lambda x: shape(json.loads(x)))\n",
    "        _temp_data = gpd.GeoDataFrame(_temp_data, geometry='geometry', crs=self.UTM_ESPG)\n",
    "        self.data = _temp_data\n",
    "\n",
    "        # labels\n",
    "        _temp_labels = pd.read_csv(dir_labels).drop(columns=[\"geometry\"])\n",
    "        _temp_labels['geometry'] = _temp_labels['.geo'].apply(lambda x: shape(json.loads(x)))\n",
    "        _temp_labels = gpd.GeoDataFrame(_temp_labels, geometry='geometry', crs=self.UTM_ESPG)\n",
    "        self.gdf_labels = _temp_labels\n",
    "\n",
    "        # sparse \n",
    "        self.df_sparse = pd.read_csv(dir_sparse, index_col=0) # TODO: FIX BROKEN SAVE \n",
    "\n",
    "        # points\n",
    "        with fiona.open(dir_points) as src:\n",
    "            self.points = gpd.GeoDataFrame.from_features(src, crs=src.crs)\n",
    "\n",
    "        # self.data = gpd.read_file(dir_data)\n",
    "        # self.gdf_labels = gpd.read_file(dir_labels)\n",
    "        # self.df_sparse = pd.read_csv(dir_sparse, index_col=0)\n",
    "        # self.points = gpd.read_file(dir_points)\n",
    "\n",
    "        print(f\"Data reloaded from {dir_data}, {dir_labels} and {dir_sparse}.\")\n",
    "\n",
    "    ##################################################################################################################################################################\n",
    "    # ================================================================== SAVE AND RESTORE ========================================================================== #\n",
    "    ##################################################################################################################################################################\n",
    "\n",
    "    \n",
    "\n",
    "    ##################################################################################################################################################################\n",
    "    # ================================================================== EXPORT FUNCTIONS ========================================================================== #\n",
    "    ##################################################################################################################################################################\n",
    "\n",
    "    # generate tif \n",
    "    @staticmethod\n",
    "    def os_path_chcker(output_dir, postfix=\".tif\", NAME_CODE_LIM=8, FLAG_APPEND_POSTFIX=True):\n",
    "        \"\"\"\n",
    "            Ensures that the output directory is valid, exists and can be written to.\n",
    "\n",
    "            This is a simple function that does three things:\n",
    "                1. Checks if the directory exists, if not creates it.\n",
    "                2. Checks if the file name is valid (and not empty, else creates a unique filename).\n",
    "                3. (Optional) Appends a postfix to the file name if it does not already end with it.\n",
    "\n",
    "        Args:\n",
    "            output_dir (str): The directory path to check.\n",
    "            postfix (str, optional): The postfix to append to the file name if it does not already end with it. Default is \".tif\".\n",
    "            NAME_CODE_LIM (int, optional): The length of the hex code to generate for filename. Default is 8.\n",
    "            FLAG_APPEND_POSTFIX (bool, optional): Whether to append the postfix if the file name does not end with it. Default is True.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # path existance check\n",
    "        if not os.path.exists(os.path.dirname(output_dir)):\n",
    "            os.makedirs(os.path.dirname(output_dir))\n",
    "            print(f\"Created directory: {os.path.dirname(output_dir)}\")\n",
    "\n",
    "        # file name existance check\n",
    "        flag_filename = not os.path.basename(output_dir) or output_dir.endswith(\"/\")\n",
    "        while flag_filename:\n",
    "            print(\"Generating new file name...\")\n",
    "            # assign unique name to the tif file\n",
    "            new_file_name = f\"{os.urandom(NAME_CODE_LIM).hex()}{postfix}\"\n",
    "            if not os.path.exists(output_dir + new_file_name):\n",
    "                output_dir += new_file_name\n",
    "                flag_filename = False\n",
    "                print(f\"New File Name: {output_dir}\")\n",
    "\n",
    "        # check labelled correctly \n",
    "        if FLAG_APPEND_POSTFIX and not output_dir.endswith(postfix):\n",
    "            print(f\"Output directory {output_dir} does not end with .tif, appending .tif\")\n",
    "            output_dir += {postfix}\n",
    "            \n",
    "        return output_dir\n",
    "\n",
    "    def export_to_tif(self, df, bands, output_dir, res=50, UTM_ESPG=32638, EPSG=4326):\n",
    "        \"\"\"\n",
    "            Exports a DataFrame generated by PlotToSat to a GeoTIFF file. \n",
    "\n",
    "            Note: df files MUST CONTAIN:\n",
    "            - `.geo` column with GeoJSON geometries.\n",
    "            - `file_name` column with unique identifiers for each row.\n",
    "            - 1 Unique band labelled in `bands` list - this CAN BE LABELLED CLUSTERS. \n",
    "\n",
    "            Expected formats:\n",
    "                Time-Series data should be in a DataFrame with 'month_band' columns (e.g., '0_B1', '1_B2', etc.).\n",
    "                if a band is provideda e.g.m B1 but there are no pre-fix values this data will be assumed to be a single band AS-IS, and will be included in the output just as that band alone. \n",
    "\n",
    "            Args:\n",
    "                df (pd.DataFrame): PlotToSat Style pandas DataFrame containing time-series data or single band data. Must have file_name and `.geo` geometry columns.\n",
    "                bands (list): List of band names to include in the output. e.g., ['B1', 'B2', 'B3'] or ['SingleBand', etc.] can be mixed with single band data.\n",
    "                output_dir (str): Output file directory for the GeoTIFF.\n",
    "                res (int, optional): Resolution of the output raster in meters. Default is 50m.\n",
    "                UTM_ESPG (int, optional): EPSG code for the UTM coordinate reference system. Default is 32638.\n",
    "                \n",
    "\n",
    "\n",
    "                # EPSG (int, optional): EPSG code for the coordinate reference system.\n",
    "        \"\"\"\n",
    "\n",
    "        # Ensure output directory is valid, exists and can be written to.\n",
    "        file = self.os_path_chcker(output_dir, postfix=\".tif\", NAME_CODE_LIM=8, FLAG_APPEND_POSTFIX=True)\n",
    "\n",
    "\n",
    "        # Sort the Bands into single and time-series band data. \n",
    "        column_heads = df.columns.tolist()\n",
    "\n",
    "        \n",
    "        # all available bands in the data\n",
    "        band_columns = [col for col in column_heads if any(col.endswith(band) for band in bands)]\n",
    "\n",
    "\n",
    "        # Acceptable bands to process \n",
    "        acceptable_lst = []\n",
    "        for col in bands:\n",
    "            if any(col.startswith(f\"{i}_\") for i in range(12)):\n",
    "                # must be non-prefix and only one band of that ts \n",
    "                if col not in acceptable_lst and any(coli for coli in band_columns if coli == col):\n",
    "                    acceptable_lst.append(col)\n",
    "                # acceptable_lst.append(col)\n",
    "            else:\n",
    "                # must exist in band_columns and take all \n",
    "                appended = False\n",
    "                for i in range(12):\n",
    "                    if any(coli for coli in band_columns if coli == f\"{i}_{col}\"):\n",
    "                        if f\"{i}_{col}\" not in acceptable_lst:\n",
    "                            # add only if not already in list     \n",
    "                            acceptable_lst.append(f\"{i}_{col}\")\n",
    "                            appended = True\n",
    "\n",
    "                if appended == False:\n",
    "                    # if not appended must be a unique column \n",
    "                    acceptable_lst.append(col)\n",
    "        \n",
    "        band_columns = acceptable_lst\n",
    "\n",
    "    \n",
    "        geometry = df[\".geo\"].apply(lambda x: shape(json.loads(x)))\n",
    "        gdf = gpd.GeoDataFrame(df[band_columns].copy(), geometry=geometry, crs=f\"EPSG:{EPSG}\") # EPSG not UTM_ESPG else will raise an error\n",
    "\n",
    "        gdf_utm = gdf.to_crs(epsg=UTM_ESPG)\n",
    "\n",
    "        minx, miny, maxx, maxy = gdf_utm.total_bounds\n",
    "        width = int((maxx - minx) / res)\n",
    "        height = int((maxy - miny) / res)\n",
    "\n",
    "        transform = from_origin(minx, maxy, res, res)\n",
    "\n",
    "        if width <= 0 or height <= 0:\n",
    "            raise ValueError(f\"Invalid raster dimensions (width={width}, height={height}). Check CRS and resolution.\")\n",
    "\n",
    "\n",
    "        # Build Raster Stack\n",
    "        rasters = []\n",
    "        for band in band_columns:\n",
    "            values = gdf_utm[band]\n",
    "            shapes = ((geom, val) for geom, val in zip(gdf_utm.geometry, values))\n",
    "            raster = rasterize(\n",
    "                shapes=shapes,\n",
    "                out_shape=(height, width),\n",
    "                transform=transform,\n",
    "                dtype=\"float32\",\n",
    "                fill=np.NaN,  # Fill with NaN values \n",
    "            )\n",
    "\n",
    "            rasters.append(raster)\n",
    "\n",
    "        raster_stack = raster_stack = np.stack(rasters, axis=0) if len(rasters) >= 2 else rasters\n",
    "\n",
    "\n",
    "        # Save rasters to GeoTIFF \n",
    "        with rasterio.open(\n",
    "            file,\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=len(band_columns),\n",
    "            dtype=\"float32\",\n",
    "            crs=f\"EPSG:{UTM_ESPG}\",\n",
    "            transform=transform,\n",
    "            nodata=np.NaN,  # Set NoData value to NaN\n",
    "        ) as dst:\n",
    "            for i, band in enumerate(band_columns):\n",
    "                dst.write(raster_stack[i], i + 1)\n",
    "                dst.set_band_description(i + 1, band) # Keep band discription!!!\n",
    "\n",
    "\n",
    "    def __convert_to_map__(self):\n",
    "        \"\"\"\n",
    "        Converts the sparse DataFrame of multiple cluster label columns to a single-column label prediction\n",
    "        based on majority voting from known labels.\n",
    "\n",
    "        Args:\n",
    "            df_sparse (pd.DataFrame): DataFrame with 'cluster_label_*' columns and index as file_name.\n",
    "            df_data (pd.DataFrame): Original data containing '.geo' and any other metadata.\n",
    "            gdf_labelled (GeoDataFrame): GeoDataFrame with true labels and index as file_name.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame indexed by file_name, with predicted label (or None if unassignable).\n",
    "        \"\"\"\n",
    "\n",
    "        df_sparse = self.df_sparse.copy()\n",
    "        df_data = self.data.copy()\n",
    "        gdf_labelled = self.gdf_labels.copy()\n",
    "\n",
    "        # Ensure labels column exists\n",
    "        if 'class' not in gdf_labelled.columns:\n",
    "            raise ValueError(\"gdf_labelled must contain a 'class' column with ground truth labels.\")\n",
    "\n",
    "        predictions = pd.Series(index=df_sparse.index, dtype=object)\n",
    "\n",
    "        for col in df_sparse.columns:\n",
    "            if not col.startswith(\"cluster_label_\"):\n",
    "                continue\n",
    "\n",
    "            # Get cluster IDs and their associated true labels\n",
    "            cluster_ids = df_sparse[col]\n",
    "            known_labels = gdf_labelled['class']\n",
    "\n",
    "            # Build mapping: cluster_id -> list of known labels\n",
    "            cluster_to_labels = {}\n",
    "            for file_name, cluster_id in cluster_ids.items():\n",
    "                if file_name in known_labels and pd.notna(known_labels[file_name]):\n",
    "                    cluster_to_labels.setdefault(cluster_id, []).append(known_labels[file_name])\n",
    "\n",
    "            # Compute majority label for each cluster\n",
    "            cluster_to_majority = {}\n",
    "            for cluster_id, labels in cluster_to_labels.items():\n",
    "                if not labels:\n",
    "                    cluster_to_majority[cluster_id] = None\n",
    "                else:\n",
    "                    label_counts = Counter(labels)\n",
    "                    most_common = label_counts.most_common()\n",
    "                    top_label = most_common[0][0] if len(most_common) == 1 or most_common[0][1] != most_common[1][1] \\\n",
    "                        else np.random.choice([l for l, c in most_common if c == most_common[0][1]])\n",
    "                    cluster_to_majority[cluster_id] = top_label\n",
    "\n",
    "            # Assign predicted label per row\n",
    "            for idx in df_sparse.index:\n",
    "                cluster_id = df_sparse.at[idx, col]\n",
    "                label = cluster_to_majority.get(cluster_id, None)\n",
    "                if pd.isna(predictions.at[idx]) and label is not None:\n",
    "                    predictions.at[idx] = label\n",
    "\n",
    "        # Create output DataFrame\n",
    "        result_df = pd.DataFrame({'predicted_label': predictions})\n",
    "\n",
    "        # Join metadata like `.geo` if needed\n",
    "        if '.geo' in df_data.columns:\n",
    "            result_df = result_df.join(df_data['.geo'])\n",
    "\n",
    "        return result_df\n",
    "\n",
    "\n",
    "    def create_map(self, filename=\"\"):\n",
    "        predictions = self.__convert_to_map__()\n",
    "\n",
    "        # tif creation\n",
    "        predictions['numeric_label'] = predictions['predicted_label'].map(self.mapping)\n",
    "        output_path = self.os_path_chcker(filename)\n",
    "        self.export_to_tif(predictions, bands=['numeric_label'], output_dir=output_path)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    ##################################################################################################################################################################\n",
    "    # =============================================================== PRE-PROCESSING =============================================================================== #\n",
    "    ##################################################################################################################################################################\n",
    "\n",
    "    def update_row_labels(self, gdf_labels):\n",
    "        df_gdf = self.gdf_labels.copy()\n",
    "        labels_gdf = gdf_labels.copy()\n",
    "\n",
    "        df_gdf['label'] = None\n",
    "        for _, label_row in labels_gdf.iterrows():\n",
    "            print(f\"progress: {_}/{len(labels_gdf)} labels processed.\")\n",
    "            label = label_row['label']\n",
    "            \n",
    "            # Check each point until assigned or dropped\n",
    "            for idx, point in df_gdf.iterrows():\n",
    "                if label_row.geometry.intersects(point.geometry):\n",
    "                    df_gdf.at[idx, 'class'] = label\n",
    "                    break\n",
    "\n",
    "        self.gdf_labels = df_gdf\n",
    "\n",
    "        return df_gdf\n",
    "\n",
    "\n",
    "    def build_row_labels(self):\n",
    "        \"\"\"\n",
    "        Builds a DataFrame with labelled polygons based on the points in the GeoDataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (GeoDataFrame): The GeoDataFrame containing the points.\n",
    "            labels (GeoDataFrame): The GeoDataFrame containing the polygons and their labels.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame with the labels for each point.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Prepare and Ensure in GeoDataFrame format\n",
    "        df_gdf = self.data.copy()\n",
    "        if df_gdf is type(pd.DataFrame):\n",
    "            df_gdf = self.convert_df_to_geodf(df_gdf, geo_col='.geo', crs=f\"EPSG:{self.UTM_ESPG}\")\n",
    "        labels_gdf = self.points.copy()\n",
    "\n",
    "        # check for intersections and assign labels\n",
    "        df_gdf['label'] = None\n",
    "        for _, label_row in labels_gdf.iterrows():\n",
    "            print(f\"progress: {_}/{len(labels_gdf)} labels processed.\")\n",
    "            label = label_row['label']\n",
    "            \n",
    "            # Check each point until assigned or dropped\n",
    "            for idx, point in df_gdf.iterrows():\n",
    "                if label_row.geometry.intersects(point.geometry):\n",
    "                    df_gdf.at[idx, 'class'] = label\n",
    "                    break\n",
    "\n",
    "        self.gdf_labels = df_gdf\n",
    "\n",
    "        return df_gdf\n",
    "    \n",
    "    ##################################################################################################################################################################\n",
    "    # ================================================================ Label Recomendations ======================================================================== #\n",
    "    ##################################################################################################################################################################\n",
    "\n",
    "    def create_recommendations(self, filename=\"/\"):\n",
    "        \"\"\"\n",
    "            Based on the Points Creates a map of recommendations for labelling the points in the subregions. \n",
    "\n",
    "            The higher the value the higher the recommendation to label the point. \n",
    "        \"\"\"\n",
    "\n",
    "        # resolution (m)\n",
    "        res = 50\n",
    "\n",
    "        # labels \n",
    "        labels = self.points.copy()\n",
    "        labelled_data = self.gdf_labels.copy()\n",
    "        data = self.data.copy()\n",
    "\n",
    "        # # height map from truth labels \n",
    "        # max_height = 100.0\n",
    "        # data['distance_value'] = 0.0 # old is 0.0\n",
    "\n",
    "        # for _, label_geometry in labels.iterrows():\n",
    "        #     print(f\"progress: {_}/{len(labels)} labels processed.\")\n",
    "        #     label = label_geometry['label']\n",
    "        #     if pd.isna(label):\n",
    "        #         continue\n",
    "            \n",
    "        #     # Calculate distance map where lowest values are the points closest to the label geometry\n",
    "        #     distances = data.geometry.distance(label_geometry.geometry)\n",
    "        #     # data['distance_value'] += (max_height - distances) / max_height\n",
    "        #     data['distance_value'] += distances / max_height\n",
    "\n",
    "        # # normalise by the number of labels\n",
    "        # if len(labels) > 0:\n",
    "        #     data['distance_value'] /= len(labels)\n",
    "\n",
    "        # # flip vlaues by max to create a recommendation map\n",
    "        # data['distance_value'] = max_height - data['distance_value']\n",
    "\n",
    "\n",
    "        max_height = 100.0\n",
    "        data['distance_value'] = 0.0 \n",
    "\n",
    "        for _, label_geometry in labels.iterrows():\n",
    "            print(f\"progress: {_}/{len(labels)} labels processed.\")\n",
    "\n",
    "            distances = data.geometry.distance(label_geometry.geometry) \n",
    "\n",
    "            # if distance is greater than 500m away ignore so set to 0 \n",
    "            distances[distances > 500] = 0.0\n",
    "\n",
    "            # normal around the point from 100 to 0.0 at edge\n",
    "            data['distance_value'] += (max_height - distances) / max_height\n",
    "\n",
    "            # take max value when compared between data['distance_value'] and the new value\n",
    "            data['distance_value'] = data['distance_value'].combine(data['distance_value'], max)  \n",
    "            \n",
    "        try:\n",
    "            self.export_to_tif(data, bands=['distance_value'], output_dir=self.os_path_chcker(filename, postfix=\".tif\", NAME_CODE_LIM=8, FLAG_APPEND_POSTFIX=True), res=50, UTM_ESPG=self.UTM_ESPG, EPSG=self.EPSG)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}, \\n Could not export recommendations to TIF, Returing DataFrame, so you can try again (This may be filename related!)\")\n",
    "\n",
    "        return data\n",
    "        \n",
    "\n",
    "    \n",
    "    ##################################################################################################################################################################\n",
    "    # ========================================================================== CLUSTERING ======================================================================== #\n",
    "    ##################################################################################################################################################################\n",
    "        \n",
    "    def fit(self, cluster_fn, index_column='file_name'):\n",
    "        \"\"\"\n",
    "            Fits the clustering model to the data.\n",
    "            This method should be implemented in subclasses.\n",
    "        \"\"\"\n",
    "\n",
    "        subregions_data = []\n",
    "\n",
    "        for _, subregion in self.subregions.iterrows():\n",
    "            # clip the data to the subregion\n",
    "            # based on .geo column drop all rows that do not intersect with the polygon\n",
    "\n",
    "            df_clipped = self.clip_dataframe(subregion.geometry, self.data)\n",
    "            df_clipped = df_clipped.dropna()\n",
    "            df_clipped = df_clipped.drop(columns=[\"system:index\", \".geo\"]) # unessusary columns for clustering\n",
    "            # df_clipped = df_clipped.set_index(\"file_name\")\n",
    "            df_clipped = df_clipped.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            if df_clipped.empty:\n",
    "                print(\"No data points found in this subregion.\")\n",
    "                continue\n",
    "\n",
    "            subregions_data.append(df_clipped)\n",
    "\n",
    "        matrix = pd.DataFrame()\n",
    "        index_number = 0\n",
    "\n",
    "        for subregion_df in subregions_data:\n",
    "            print(f\"Clustering {len(subregion_df)} points from subregion.\")\n",
    "\n",
    "            for i in range(self.passes):\n",
    "                # Perform clustering\n",
    "                labels, indecies = kmeans_clustering(subregion_df, k=10)  # TODOP: replace with cluster_fn\n",
    "\n",
    "                col_name = f'cluster_label_{index_number}'\n",
    "\n",
    "                # Temporary DataFrame\n",
    "                temp_df = pd.DataFrame({col_name: labels, 'file_name': indecies})\n",
    "\n",
    "                # Group in case of duplicates\n",
    "                temp_grouped = temp_df.groupby('file_name')[col_name].first()\n",
    "\n",
    "                # Convert to DataFrame for merging\n",
    "                temp_grouped = temp_grouped.to_frame()\n",
    "\n",
    "                print(f\"temp columns: {temp_grouped.columns}\")\n",
    "\n",
    "                # Merge with main matrix\n",
    "                matrix = matrix.join(temp_grouped, how='outer') if not matrix.empty else temp_grouped\n",
    "\n",
    "                index_number += 1\n",
    "                print(len(matrix.columns), \"columns in the matrix after clustering.\")\n",
    "                print(len(matrix), \"rows in the matrix after clustering.\")\n",
    "\n",
    "        matrix = matrix.join(self.data[[\".geo\"]], how='outer')\n",
    "        self.df_sparse = matrix\n",
    "\n",
    "        return matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d215079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reloaded from temp_test/test1_data.geojson, temp_test/test1_labels.geojson and temp_test/test1_sparse.csv.\n",
      "progress: 0/503 labels processed.\n",
      "progress: 1/503 labels processed.\n",
      "progress: 2/503 labels processed.\n",
      "progress: 3/503 labels processed.\n",
      "progress: 4/503 labels processed.\n",
      "progress: 5/503 labels processed.\n",
      "progress: 6/503 labels processed.\n",
      "progress: 7/503 labels processed.\n",
      "progress: 8/503 labels processed.\n",
      "progress: 9/503 labels processed.\n",
      "progress: 10/503 labels processed.\n",
      "progress: 11/503 labels processed.\n",
      "progress: 12/503 labels processed.\n",
      "progress: 13/503 labels processed.\n",
      "progress: 14/503 labels processed.\n",
      "progress: 15/503 labels processed.\n",
      "progress: 16/503 labels processed.\n",
      "progress: 17/503 labels processed.\n",
      "progress: 18/503 labels processed.\n",
      "progress: 19/503 labels processed.\n",
      "progress: 20/503 labels processed.\n",
      "progress: 21/503 labels processed.\n",
      "progress: 22/503 labels processed.\n",
      "progress: 23/503 labels processed.\n",
      "progress: 24/503 labels processed.\n",
      "progress: 25/503 labels processed.\n",
      "progress: 26/503 labels processed.\n",
      "progress: 27/503 labels processed.\n",
      "progress: 28/503 labels processed.\n",
      "progress: 29/503 labels processed.\n",
      "progress: 30/503 labels processed.\n",
      "progress: 31/503 labels processed.\n",
      "progress: 32/503 labels processed.\n",
      "progress: 33/503 labels processed.\n",
      "progress: 34/503 labels processed.\n",
      "progress: 35/503 labels processed.\n",
      "progress: 36/503 labels processed.\n",
      "progress: 37/503 labels processed.\n",
      "progress: 38/503 labels processed.\n",
      "progress: 39/503 labels processed.\n",
      "progress: 40/503 labels processed.\n",
      "progress: 41/503 labels processed.\n",
      "progress: 42/503 labels processed.\n",
      "progress: 43/503 labels processed.\n",
      "progress: 44/503 labels processed.\n",
      "progress: 45/503 labels processed.\n",
      "progress: 46/503 labels processed.\n",
      "progress: 47/503 labels processed.\n",
      "progress: 48/503 labels processed.\n",
      "progress: 49/503 labels processed.\n",
      "progress: 50/503 labels processed.\n",
      "progress: 51/503 labels processed.\n",
      "progress: 52/503 labels processed.\n",
      "progress: 53/503 labels processed.\n",
      "progress: 54/503 labels processed.\n",
      "progress: 55/503 labels processed.\n",
      "progress: 56/503 labels processed.\n",
      "progress: 57/503 labels processed.\n",
      "progress: 58/503 labels processed.\n",
      "progress: 59/503 labels processed.\n",
      "progress: 60/503 labels processed.\n",
      "progress: 61/503 labels processed.\n",
      "progress: 62/503 labels processed.\n",
      "progress: 63/503 labels processed.\n",
      "progress: 64/503 labels processed.\n",
      "progress: 65/503 labels processed.\n",
      "progress: 66/503 labels processed.\n",
      "progress: 67/503 labels processed.\n",
      "progress: 68/503 labels processed.\n",
      "progress: 69/503 labels processed.\n",
      "progress: 70/503 labels processed.\n",
      "progress: 71/503 labels processed.\n",
      "progress: 72/503 labels processed.\n",
      "progress: 73/503 labels processed.\n",
      "progress: 74/503 labels processed.\n",
      "progress: 75/503 labels processed.\n",
      "progress: 76/503 labels processed.\n",
      "progress: 77/503 labels processed.\n",
      "progress: 78/503 labels processed.\n",
      "progress: 79/503 labels processed.\n",
      "progress: 80/503 labels processed.\n",
      "progress: 81/503 labels processed.\n",
      "progress: 82/503 labels processed.\n",
      "progress: 83/503 labels processed.\n",
      "progress: 84/503 labels processed.\n",
      "progress: 85/503 labels processed.\n",
      "progress: 86/503 labels processed.\n",
      "progress: 87/503 labels processed.\n",
      "progress: 88/503 labels processed.\n",
      "progress: 89/503 labels processed.\n",
      "progress: 90/503 labels processed.\n"
     ]
    }
   ],
   "source": [
    "mapping = {\n",
    "            None: 0,\n",
    "            np.NaN: 0,\n",
    "            \"NaN\": 0,\n",
    "            \"None\": 0,\n",
    "            \"Water\": 1,\n",
    "            \"Agricultural\": 2,\n",
    "            \"Urban\": 3,\n",
    "            \"Wasteland\": 4,\n",
    "        }\n",
    "\n",
    "\n",
    "# THIS WORKS \n",
    "c = cluster(chunks, df1, points=labels, mapping=mapping, passes=1)\n",
    "c.reload(\"temp_test/test1_data.geojson\", \"temp_test/test1_labels.geojson\", \"temp_test/test1_sparse.csv\", \"temp_test/test1_points.geojson\")\n",
    "c.create_recommendations()\n",
    "# matrix = c.fit(kmeans_clustering)\n",
    "# c.create_map(\"/temptest2.tif\")\n",
    "\n",
    "# NOTE: test1_sparse.csv does NOT HAVE CORRECT DATA \n",
    "\n",
    "\n",
    "\n",
    "# c.build_row_labels() # TODO: add passes \n",
    "# self.data = gpd.read_file(dir_data)\n",
    "# self.gdf_labels = gpd.read_file(dir_labels)\n",
    "# self.df_sparse = pd.read_csv(dir_sparse, index_col=0)\n",
    "# self.points = gpd.read_file(dir_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58e898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OLD OLD OLD OLD OLD OLD OLD OLD \n",
    "\n",
    "def save_processed_label_data(geodf, filename):\n",
    "    \"\"\"Saves the processed GeoDataFrame to a file.\"\"\"\n",
    "    if isinstance(geodf, gpd.GeoDataFrame):\n",
    "        geodf.to_file(filename, driver='GeoJSON')\n",
    "        print(f\"GeoDataFrame saved to {filename}\")\n",
    "    elif isinstance(geodf, pd.DataFrame):\n",
    "        geodf.to_csv(filename, index=True)\n",
    "        print(f\"DataFrame saved to {filename}\")\n",
    "\n",
    "# save_processed_label_data(c.gdf_labels, \"temp_test/test1_labels.geojson\")\n",
    "# save_processed_label_data(c.df_sparse, \"temp_test/test1_sparse.csv\")\n",
    "# save_processed_label_data(c.data, \"temp_test/test1_data.geojson\")\n",
    "# save_processed_label_data(c.points, \"temp_test/test1_points.geojson\")\n",
    "# save_processed_label_data(c.subregions, \"temp_test/test1_subregions.geojson\")\n",
    "\n",
    "\n",
    "# OLDER OLDER OLDER OLDER OLDER \n",
    "# # save c.df_sparse to a file #TODOFINDMEREF\n",
    "# save_processed_label_data(c.df_sparse, \"data/df_sparse_data.json\")\n",
    "# save_processed_label_data(c.gdf_labels, \"data/labels.geojson\")\n",
    "###save_processed_label_data(c.data, \"data/subregions.geojson\") # may be useless "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d30fb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818f9a93bd974bb4a8afcd7fa645a64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[34.22282359393232, 43.778616017576226], controls=(WidgetControl(options=['position', 'transparent_…"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wasteland_update_map = gen_basemap(basemap_url, aoi=chunks)\n",
    "# wasteland_update_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6522649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 0/74 labels processed.\n",
      "progress: 1/74 labels processed.\n",
      "progress: 2/74 labels processed.\n",
      "progress: 3/74 labels processed.\n",
      "progress: 4/74 labels processed.\n",
      "progress: 5/74 labels processed.\n",
      "progress: 6/74 labels processed.\n",
      "progress: 7/74 labels processed.\n",
      "progress: 8/74 labels processed.\n",
      "progress: 9/74 labels processed.\n",
      "progress: 10/74 labels processed.\n",
      "progress: 11/74 labels processed.\n",
      "progress: 12/74 labels processed.\n",
      "progress: 13/74 labels processed.\n",
      "progress: 14/74 labels processed.\n",
      "progress: 15/74 labels processed.\n",
      "progress: 16/74 labels processed.\n",
      "progress: 17/74 labels processed.\n",
      "progress: 18/74 labels processed.\n",
      "progress: 19/74 labels processed.\n",
      "progress: 20/74 labels processed.\n",
      "progress: 21/74 labels processed.\n",
      "progress: 22/74 labels processed.\n",
      "progress: 23/74 labels processed.\n",
      "progress: 24/74 labels processed.\n",
      "progress: 25/74 labels processed.\n",
      "progress: 26/74 labels processed.\n",
      "progress: 27/74 labels processed.\n",
      "progress: 28/74 labels processed.\n",
      "progress: 29/74 labels processed.\n",
      "progress: 30/74 labels processed.\n",
      "progress: 31/74 labels processed.\n",
      "progress: 32/74 labels processed.\n",
      "progress: 33/74 labels processed.\n",
      "progress: 34/74 labels processed.\n",
      "progress: 35/74 labels processed.\n",
      "progress: 36/74 labels processed.\n",
      "progress: 37/74 labels processed.\n",
      "progress: 38/74 labels processed.\n",
      "progress: 39/74 labels processed.\n",
      "progress: 40/74 labels processed.\n",
      "progress: 41/74 labels processed.\n",
      "progress: 42/74 labels processed.\n",
      "progress: 43/74 labels processed.\n",
      "progress: 44/74 labels processed.\n",
      "progress: 45/74 labels processed.\n",
      "progress: 46/74 labels processed.\n",
      "progress: 47/74 labels processed.\n",
      "progress: 48/74 labels processed.\n",
      "progress: 49/74 labels processed.\n",
      "progress: 50/74 labels processed.\n",
      "progress: 51/74 labels processed.\n",
      "progress: 52/74 labels processed.\n",
      "progress: 53/74 labels processed.\n",
      "progress: 54/74 labels processed.\n",
      "progress: 55/74 labels processed.\n",
      "progress: 56/74 labels processed.\n",
      "progress: 57/74 labels processed.\n",
      "progress: 58/74 labels processed.\n",
      "progress: 59/74 labels processed.\n",
      "progress: 60/74 labels processed.\n",
      "progress: 61/74 labels processed.\n",
      "progress: 62/74 labels processed.\n",
      "progress: 63/74 labels processed.\n",
      "progress: 64/74 labels processed.\n",
      "progress: 65/74 labels processed.\n",
      "progress: 66/74 labels processed.\n",
      "progress: 67/74 labels processed.\n",
      "progress: 68/74 labels processed.\n",
      "progress: 69/74 labels processed.\n",
      "progress: 70/74 labels processed.\n",
      "progress: 71/74 labels processed.\n",
      "progress: 72/74 labels processed.\n",
      "progress: 73/74 labels processed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>.geo</th>\n",
       "      <th>numeric_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[43.99813739...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[44.10438435...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[43.99813739...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[43.99922097...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[44.00030452...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[43.91080588...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[43.91079693...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[43.91078360...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[43.91077465...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372312</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[43.91164867...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372313 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       predicted_label                                               .geo  \\\n",
       "0                  NaN  {\"type\":\"Polygon\",\"coordinates\":[[[43.99813739...   \n",
       "1                  NaN  {\"type\":\"Polygon\",\"coordinates\":[[[44.10438435...   \n",
       "2                  NaN  {\"type\":\"Polygon\",\"coordinates\":[[[43.99813739...   \n",
       "3                  NaN  {\"type\":\"Polygon\",\"coordinates\":[[[43.99922097...   \n",
       "4                  NaN  {\"type\":\"Polygon\",\"coordinates\":[[[44.00030452...   \n",
       "...                ...                                                ...   \n",
       "372308             NaN  {\"type\":\"Polygon\",\"coordinates\":[[[43.91080588...   \n",
       "372309             NaN  {\"type\":\"Polygon\",\"coordinates\":[[[43.91079693...   \n",
       "372310             NaN  {\"type\":\"Polygon\",\"coordinates\":[[[43.91078360...   \n",
       "372311             NaN  {\"type\":\"Polygon\",\"coordinates\":[[[43.91077465...   \n",
       "372312             NaN  {\"type\":\"Polygon\",\"coordinates\":[[[43.91164867...   \n",
       "\n",
       "        numeric_label  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "372308              0  \n",
       "372309              0  \n",
       "372310              0  \n",
       "372311              0  \n",
       "372312              0  \n",
       "\n",
       "[372313 rows x 3 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wasteland_update_labels = collect_points_from_geemap(wasteland_update_map, label=\"Wasteland\")\n",
    "# c.update_row_labels(wasteland_update_labels)\n",
    "# c.create_map(\"/temptest3.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62965e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ts_cluster():\n",
    "\n",
    "    yearly_clusters = []\n",
    "\n",
    "    def __init__(self, ts_point_labels, data_dir, mapping, passes=6):\n",
    "        \"\"\"\n",
    "            Initializes the ts_cluster object with time-series point labels, data directory, mapping, and number of passes.\n",
    "        \"\"\"\n",
    "        self.ts_point_labels = ts_point_labels          # expected labels in format year_start, year_end, label and point geometry \n",
    "        self.data_dir = data_dir                        # expected to have file_dir and year columns in pd.DataFrame format  \n",
    "        self.mapping = mapping                          # mapping for labels to numeric values \n",
    "        self.passes = passes                            # int \n",
    "    \n",
    "\n",
    "    def __create_shared_label_list__(self):\n",
    "        \"\"\"\n",
    "            Creates a list of shared labels acrross ALL time-series points, such that it can act as a base for labels in the clustering process.\n",
    "        \"\"\"\n",
    "\n",
    "        shared_labels = pd.DataFrame(columns=[\"year_start\", \"year_end\", \"label\", \"geometry\"])\n",
    "        non_shared_labels = pd.DataFrame(columns=[\"year_start\", \"year_end\", \"label\", \"geometry\"])\n",
    "\n",
    "        min_year = self.data_dir['year'].min()\n",
    "        max_year = self.data_dir['year'].max()\n",
    "\n",
    "        # if years between (incluside) are in ts_point_labels, then add to shared_labels else add to non_shared_labels\n",
    "        for year in range(min_year, max_year + 1):\n",
    "            if year in self.ts_point_labels['year_start'].values:\n",
    "                shared_labels = shared_labels.append(self.ts_point_labels[self.ts_point_labels['year_start'] == year], ignore_index=True)\n",
    "\n",
    "        # else \n",
    "        non_shared_labels = self.ts_point_labels[~self.ts_point_labels['year_start'].isin(shared_labels['year_start'])]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cdb011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year: 2019\n",
      "Processing year: 2020\n",
      "Processing year: 2021\n",
      "Processing year: 2022\n",
      "Processing year: 2023\n",
      "Processing year: 2024\n"
     ]
    }
   ],
   "source": [
    "x_1 = 2019\n",
    "x_2 = 2024\n",
    "\n",
    "for y in range(x_1, x_2 + 1):\n",
    "    print(f\"Processing year: {y}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
