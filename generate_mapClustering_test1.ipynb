{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31236cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cluster as cl\n",
    "import cluster_ts as cl_ts\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely import wkt\n",
    "import fiona\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e19c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# basemap \n",
    "basemap_url = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}'\n",
    "\n",
    "# centeral point of Samarra \n",
    "df_sites = pd.DataFrame({\n",
    "    \"longitude\": [43.823543],\n",
    "    \"latitude\": [34.340989],\n",
    "    \"name\": [\"Samarra Archaeological City\"],\n",
    "    \"category\": [\"Cultural\"],\n",
    "    \"date inscribed\": [\"2007\"],\n",
    "    \"region\": [\"Arab States\"],\n",
    "    \"url\": [\"https://whc.unesco.org/en/list/276\"],\n",
    "    \"iso\": [[\"IQ\"]]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91cc69",
   "metadata": {},
   "source": [
    "# Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5895868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subregions created: 35\n"
     ]
    }
   ],
   "source": [
    "def create_subregions(chunks, sift_percentage_lon=0.5, sift_percentage_lat=0.415):\n",
    "    \"\"\"\n",
    "        Shifts all polygons to 8 positions based on half the length in longitude and latitude, to create subregions - one for each direction from the center.\n",
    "\n",
    "        Assumes aoi contains all similar polygons, and are similar to a square.\n",
    "\n",
    "        Parameters:\n",
    "            aoi (GeoDataFrame): The area of interest containing geometries.\n",
    "            sift_percentage (float): Percentage of the length to shift the center point. Default is 0.5 (50%) for half the length.\n",
    "    \"\"\"\n",
    "\n",
    "    if chunks.empty:\n",
    "        return {}\n",
    "    \n",
    "    first_polygon = chunks.geometry.iloc[0]\n",
    "\n",
    "    # take top two points of the polygon and get the length between them\n",
    "    top_points = first_polygon.exterior.coords[:2]\n",
    "    length_lon = abs(top_points[0][0] - top_points[1][0])\n",
    "\n",
    "    # calculate the shift amount\n",
    "    shift_amount_lon = length_lon * sift_percentage_lon \n",
    "    shift_amount_lat = length_lon * sift_percentage_lat\n",
    "\n",
    "    shift_directions = {\n",
    "        \"left\": (-shift_amount_lon, 0),\n",
    "        \"right\": (shift_amount_lon, 0),\n",
    "        \"up\": (0, shift_amount_lat),\n",
    "        \"down\": (0, -shift_amount_lat),\n",
    "        \"top_left\": (-shift_amount_lon, shift_amount_lat),\n",
    "        \"top_right\": (shift_amount_lon, shift_amount_lat),\n",
    "        \"bottom_left\": (-shift_amount_lon, -shift_amount_lat),\n",
    "        \"bottom_right\": (shift_amount_lon, -shift_amount_lat),\n",
    "    }\n",
    "\n",
    "    subregions = []\n",
    "    aoi = chunks.copy()\n",
    "    aoi = aoi.dissolve()\n",
    "        \n",
    "    # Create subregions by shifting the geometries in all directions\n",
    "    for _, (dx, dy) in shift_directions.items():\n",
    "        gdf_shifted = chunks.copy()\n",
    "        gdf_shifted[\"geometry\"] = gdf_shifted[\"geometry\"].translate(dx, dy)\n",
    "\n",
    "        if subregions is not []:\n",
    "            for region in subregions:\n",
    "                for polygon in gdf_shifted.geometry:\n",
    "                    for region_polygon in region.geometry:\n",
    "                        if polygon.intersects(region_polygon):\n",
    "                            # calculate % of intersection\n",
    "                            intersection = polygon.intersection(region_polygon)\n",
    "                            intersection_area = intersection.area\n",
    "                            region_area = region_polygon.area\n",
    "                            intersection_percentage = intersection_area / region_area if region_area > 0 else 0\n",
    "                            \n",
    "                            if intersection_percentage > 0.5: \n",
    "                                # if too high of an overlap skip\n",
    "                                # print(f\"Dropping polygon from subregion due to high overlap: {intersection_percentage:.2%} with existing region.\")\n",
    "                                gdf_shifted = gdf_shifted[gdf_shifted.geometry != polygon]\n",
    "                                break         \n",
    "\n",
    "        subregions.append(gdf_shifted)\n",
    "\n",
    "    # Combine all into one GeoDataFrame\n",
    "    subregions = pd.concat(subregions, ignore_index=True)\n",
    "\n",
    "    # Reset index and return as GeoDataFrame\n",
    "    subregions = subregions.reset_index(drop=True)\n",
    "\n",
    "    return gpd.GeoDataFrame(subregions, crs=chunks.crs)\n",
    "\n",
    "# Chunks of Samarra Archaeological City \n",
    "with fiona.open(\"chunks_new.shp\") as src:\n",
    "    chunks = gpd.GeoDataFrame.from_features(src, crs=src.crs)\n",
    "\n",
    "# Create subregions based on the chunks\n",
    "subregions = create_subregions(chunks)\n",
    "subregions = pd.concat([subregions, chunks], ignore_index=True)\n",
    "\n",
    "print(f\"Subregions created: {len(subregions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c33b078f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapping = {\n",
    "    \"NaN\": 0,\n",
    "    np.NaN: 0,\n",
    "    \"None\": 0,\n",
    "    \"Water\": 1,\n",
    "    \"Wetland\": 2,\n",
    "    \"Agricultural\": 3,\n",
    "    \"Urban\": 4,\n",
    "    \"Wasteland\": 5,\n",
    "} \n",
    "\n",
    "data_dir = pd.DataFrame({\n",
    "    \"dir\": [f\"data/{year}.csv\" for year in range(2019, 2025)],\n",
    "    \"year\": [year for year in range(2019, 2025)]\n",
    "})\n",
    "\n",
    "labels = pd.read_csv(\"labels_backup_581.csv\")\n",
    "labels['geometry'] = labels['geometry'].apply(wkt.loads)\n",
    "labels = gpd.GeoDataFrame(labels, geometry='geometry')\n",
    "labels = labels.set_crs(\"EPSG:4326\", allow_override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4466920b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from shapely.geometry import shape\n",
    "\n",
    "def load_zones(dir):\n",
    "    \"\"\"\n",
    "        Loads in polygons zones from a directory containing GeoJSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    files = []\n",
    "\n",
    "    if dir is not [] and os.path.isfile(dir) and dir.endswith('.geojson'):\n",
    "        files = [dir]\n",
    "    else: \n",
    "        files = [f for f in os.listdir(dir) if f.endswith('.geojson')]\n",
    "    polygons = []\n",
    "\n",
    "    for file in files:\n",
    "        with fiona.open(os.path.join(dir, file)) as src:\n",
    "            for feature in src:\n",
    "                polygons.append(shape(feature['geometry']))\n",
    "\n",
    "    return polygons    \n",
    "\n",
    "zones = load_zones(\"F:/0-Projects/GEE-UNESCO/COMM514_A_12_202425/zones\")\n",
    "boundary = load_zones(\"F:/0-Projects/GEE-UNESCO/COMM514_A_12_202425/zones/boundary\")\n",
    "\n",
    "boundary = gpd.GeoDataFrame(geometry=boundary, crs=\"EPSG:4326\")\n",
    "zones = gpd.GeoDataFrame(geometry=zones, crs=\"EPSG:4326\")\n",
    "# extract the geometry from the boundary\n",
    "boundary_geom = boundary.geometry.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11db9e",
   "metadata": {},
   "source": [
    "# Clustering \n",
    "Examples of how to load, save, fit and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb5837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SETUP the class, these you must save yourself if you wish to reload \n",
    "# subregion, mapping and data_dir are required, labels can be empty and loaded later \n",
    "# requires sequential years of data in data_dir between 2019 and 2024! else this will fail \n",
    "# you can use the original cl class to do this yourself if there are year gaps, \n",
    "#                                                   ...this class just streamlines the process \n",
    "clusterer = cl_ts.cluster_ts(\n",
    "    ts_point_labels=labels,\n",
    "    data_dir=data_dir,\n",
    "    subregions=subregions,\n",
    "    mapping=mapping,\n",
    "    start_year=2019,\n",
    "    end_year=2024,\n",
    "    passes=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3fe08f",
   "metadata": {},
   "source": [
    "#### instansiate_clusters then fit OR load your clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3078f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the clusters (must be done or load the states)\n",
    "clusterer.instansiate_clusters(\n",
    "    cluster_class=cl.Cluster, \n",
    "    index_column=\"file_name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b50bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusterer.fit(save_state=\"product/gen_cluster581_15/cluster_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusterer.create_map(filename_prefix=\"product/gen_cluster581_15/cluster_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be57e5",
   "metadata": {},
   "source": [
    "#### load clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622b24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating cluster for year 2019...\n",
      "Instantiating cluster for year 2020...\n",
      "Instantiating cluster for year 2021...\n",
      "Instantiating cluster for year 2022...\n",
      "Instantiating cluster for year 2023...\n",
      "Instantiating cluster for year 2024...\n"
     ]
    }
   ],
   "source": [
    "# load clusters \n",
    "file_prefix = \"product/gen_cluster900_15/cluster_\"\n",
    "\n",
    "# load the clusters from the file\n",
    "#   this still requires the setup of the clusterer but no instansiation required\n",
    "clusterer.load_states(filename_prefix=file_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer.cluster_list[0].sparse_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a5b16",
   "metadata": {},
   "source": [
    "# Updating Labels\n",
    "This is an example using GeeMap, but this is just one way todo it, you can create the with the software/libaries of choice, they just have to fit the year_start, year_end, point format and be a GeoDataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aaea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import ipywidgets as widgets\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd \n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=\"jameswilliamchamberlain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "label_list = ['Urban', 'Agricultural', 'Water', 'Wasteland', 'Wetland', 'Other']\n",
    "date_range = [i for i in range(2019, 2025)] \n",
    "\n",
    "collection_name = \"COPERNICUS/S2_SR_HARMONIZED\"\n",
    "\n",
    "with fiona.open(\"aoi.geojson\") as src:\n",
    "    aoi = gpd.GeoDataFrame.from_features(src, crs=src.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# util functions \n",
    "def collect_points_from_geemap(map_obj, label):\n",
    "    \"\"\"\n",
    "    Collect all drawn point features from a geemap.Map that uses ee.Feature objects,\n",
    "    and return them as a GeoDataFrame with a label.\n",
    "\n",
    "    Parameters:\n",
    "        map_obj (geemap.Map): The interactive map.\n",
    "        label (str): Label to assign to all collected points.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: With geometry and 'label' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    features = map_obj.draw_features\n",
    "\n",
    "    if not features:\n",
    "        return gpd.GeoDataFrame(columns=[\"geometry\", \"label\"], geometry=\"geometry\")\n",
    "\n",
    "    points = []\n",
    "    for f in features:\n",
    "        try:\n",
    "            geom = f.geometry()  # call the method\n",
    "            if geom.getInfo()[\"type\"] == \"Point\":\n",
    "                coords = geom.coordinates().getInfo()  # [lon, lat]\n",
    "                points.append(Point(coords))\n",
    "        except Exception as e:\n",
    "            print(\"Skipping feature due to error:\", e)\n",
    "\n",
    "    if not points:\n",
    "        return gpd.GeoDataFrame(columns=[\"geometry\", \"label\"], geometry=\"geometry\")\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(geometry=points)\n",
    "    gdf[\"label\"] = label\n",
    "    gdf.set_crs(\"EPSG:4326\", inplace=True)\n",
    "    return gdf\n",
    "\n",
    "def gen_basemap(basemap_url=None, aoi=gpd.GeoDataFrame(), polygons=None):\n",
    "    \"\"\"\n",
    "        Generates a basemap with the specified URL and adds polygons if provided.\n",
    "\n",
    "        Parameters:\n",
    "            basemap_url (str): The URL of the basemap to be used.\n",
    "            polygons (GeoDataFrame, optional): Polygons to be added to the map. Defaults to None.\n",
    "            aoi (GeoDataFrame): The area of interest to be displayed on the map. (can be a set of polygons or a single polygon)\n",
    "        \n",
    "        Returns:\n",
    "            geemap.Map: A geemap map object with the specified basemap and polygons.\n",
    "    \"\"\"\n",
    "    m = geemap.Map()\n",
    "\n",
    "    if not basemap_url:\n",
    "        basemap_url = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}'\n",
    "        \n",
    "    m.add_basemap(basemap_url, name=\"Google Satellite\", attribution=\"Google\")\n",
    "\n",
    "    # center on aoi\n",
    "    if not aoi.empty:\n",
    "        m.add_gdf(aoi, layer_name=\"AOI\", style={\"color\": \"red\", \"fillColor\": \"red\", \"fillOpacity\": 0.1})\n",
    "        center_points = aoi.geometry.unary_union.centroid.coords[0]\n",
    "        m.setCenter(center_points[0], center_points[1], 10)\n",
    "    \n",
    "    if polygons is not None:\n",
    "        m.add_gdf(polygons, layer_name=\"Polygons\", style={\"color\": \"red\", \"fillColor\": \"red\", \"fillOpacity\": 0.1})\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear labels \n",
    "labels = gpd.GeoDataFrame(columns=[\"label\", \"geometry\", \"start_year\", \"end_year\"], geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744626ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = geemap.Map()\n",
    "\n",
    "def map_polygon(polygon, collection_name, layer_name, yyyymmdd1=\"2024-01-01\", yyyymmdd2=\"2024-12-29\", num_tasks=10):\n",
    "\n",
    "    # Load in Year Data to Aid in Label Creation\n",
    "    collection = ee.ImageCollection(collection_name) \\\n",
    "        .filterDate(yyyymmdd1, yyyymmdd2) \\\n",
    "        .filterBounds(polygon) \\\n",
    "        .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", 20)) \\\n",
    "        .median() \\\n",
    "        .clip(polygon)\n",
    "    \n",
    "    vis = {'min': 0, 'max': 3000, 'bands': ['B4', 'B3', 'B2']}\n",
    "\n",
    "    m.addLayer(collection, vis, layer_name)\n",
    "\n",
    "    # center map on the polygon\n",
    "    coords = polygon.geometry().centroid().coordinates().getInfo()\n",
    "    m.setCenter(coords[0], coords[1], 10)\n",
    "\n",
    "label_dropdown = widgets.Dropdown(\n",
    "    options=label_list,\n",
    "    description='Label:',\n",
    "    value=label_list[0],\n",
    ")\n",
    "\n",
    "# Plots Each Year\n",
    "for year in date_range:\n",
    "    map_polygon(geemap.geopandas_to_ee(aoi), collection_name, f\"Year {year}\", yyyymmdd1=f\"{year}-01-01\", yyyymmdd2=f\"{year}-12-29\")\n",
    "\n",
    "date_slider = widgets.SelectionSlider(\n",
    "    options=[str(year) for year in range(2019, 2025)], # 2019 to 2024 for full years\n",
    "    value='2019',\n",
    "    description='Date:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True\n",
    ")\n",
    "\n",
    "time_frame_slider = widgets.SelectionSlider(\n",
    "    options=[str(month) for month in range(1, 13)], # default 12 as its the full year \n",
    "    value='3',\n",
    "    description='timeframe:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True\n",
    ")\n",
    "\n",
    "colour_dict = {\n",
    "    \"Urban\": \"blue\",\n",
    "    \"Agricultural\": \"green\",\n",
    "    \"Water\": \"cyan\",\n",
    "    \"Wasteland\": \"brown\",\n",
    "    \"Wetland\": \"lightblue\", \n",
    "} # other is grey by default\n",
    "\n",
    "def append_label_to_points(b):\n",
    "    \"\"\"Appends the selected label to the points in the labels GeoDataFrame.\"\"\"\n",
    "\n",
    "    global labels\n",
    "\n",
    "    selected_label = label_dropdown.value\n",
    "    start_year = int(date_slider.value)\n",
    "    span = int(time_frame_slider.value)\n",
    "    end_year = start_year + span - 1\n",
    "\n",
    "    # Extract drawn features (assumed to be Points)\n",
    "    all_drawn_features = m.draw_features\n",
    "    if not all_drawn_features:\n",
    "        print(\"No features drawn.\")\n",
    "        return\n",
    "    \n",
    "    points = []\n",
    "    for feature in all_drawn_features:\n",
    "        try:\n",
    "            coords = feature.geometry().coordinates().getInfo()  # [lon, lat]\n",
    "            point = Point(coords)\n",
    "            points.append(point)\n",
    "        except Exception as e:\n",
    "            print(\"Skipping feature due to error:\", e)\n",
    "\n",
    "    # create dataframe from points\n",
    "    new_labels = gpd.GeoDataFrame({\n",
    "        'label': [selected_label] * len(points),\n",
    "        'start_year': [start_year] * len(points),\n",
    "        'end_year': [end_year] * len(points),\n",
    "        'geometry': points\n",
    "    }, crs=\"EPSG:4326\")\n",
    "\n",
    "    # Clear All Drawn Features\n",
    "    m.draw_control.clear()\n",
    "\n",
    "\n",
    "    # Append to the existing labels GeoDataFrame\n",
    "    labels = pd.concat([labels, new_labels], ignore_index=True)\n",
    "    \n",
    "\n",
    "# Label Range  \n",
    "label_output = widgets.Label()\n",
    "def update_label(*args):\n",
    "    start_year = int(date_slider.value)\n",
    "    span = int(time_frame_slider.value)\n",
    "    end_year = start_year + span - 1\n",
    "    label_output.value = f\"Selected range: {start_year} to {end_year}\"\n",
    "\n",
    "date_slider.observe(update_label, names='value')\n",
    "time_frame_slider.observe(update_label, names='value')\n",
    "\n",
    "update_label() \n",
    "\n",
    "append_btn = widgets.Button(description=\"Append Label to Points\")\n",
    "append_btn.on_click(append_label_to_points)\n",
    "\n",
    "# display(widgets.HBox([date_slider, month_slider, time_frame_slider, render_btn]))\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([date_slider, time_frame_slider]),\n",
    "    widgets.HBox([label_dropdown, label_output, append_btn]),\n",
    "]))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abad0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add from geodataframe\n",
    "def add_gdf_to_map(gdf, label, colour=\"Red\", fillOpacity=0.5):\n",
    "    if gdf.empty:\n",
    "        print(\"GeoDataFrame is empty, nothing to add.\")\n",
    "        return\n",
    "\n",
    "    m.add_gdf(gdf, layer_name=label, style={\"color\": colour, \"fillColor\": colour, \"fillOpacity\": fillOpacity})\n",
    "\n",
    "add_gdf_to_map(zones, \"Zones\", colour=\"Red\", fillOpacity=0.25)\n",
    "add_gdf_to_map(boundary, \"Boundary\", colour=\"Yellow\", fillOpacity=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd03c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = gpd.GeoDataFrame(columns=[\"label\", \"geometry\", \"start_year\", \"end_year\"], geometry=\"geometry\") # rest list (code left for ease of access)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.to_csv(\"labels_temp_319.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_labels = pd.read_csv(\"labels_temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba862dbb",
   "metadata": {},
   "source": [
    "# Update Labels and Review New Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df45ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer.update_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcda654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "clusterer.save_states(filename_prefix=\"product/gen_cluster900_15/cluster_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9319dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer.create_map(filename_prefix=\"product/gen_cluster900_15/cluster_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd7903",
   "metadata": {},
   "source": [
    "# Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d02ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load predictions old \n",
    "clusterer.cluster_list[0].predictions = pd.read_csv(\"cluster581/cluster581_2019_predictions.csv\").set_index('file_name')\n",
    "clusterer.cluster_list[1].predictions = pd.read_csv(\"cluster581/cluster581_2020_predictions.csv\").set_index('file_name')\n",
    "clusterer.cluster_list[2].predictions = pd.read_csv(\"cluster581/cluster581_2021_predictions.csv\").set_index('file_name')\n",
    "clusterer.cluster_list[3].predictions = pd.read_csv(\"cluster581/cluster581_2022_predictions.csv\").set_index('file_name')\n",
    "clusterer.cluster_list[4].predictions = pd.read_csv(\"cluster581/cluster581_2023_predictions.csv\").set_index('file_name')\n",
    "clusterer.cluster_list[5].predictions = pd.read_csv(\"cluster581/cluster581_2023_predictions.csv\").set_index('file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d000e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer.cluster_list[5].predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19677702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the prediction columns from the clusters\n",
    "# predictions = clusterer.collect_predictions()\n",
    "\n",
    "def collect_predictions_by_year(clusterer):\n",
    "    all_year_dfs = []  # To store each year's predictions\n",
    "    all_geos = pd.Series(dtype=object)  # To collect the most complete .geo values\n",
    "\n",
    "    for i, cluster in enumerate(clusterer.cluster_list):\n",
    "        year = clusterer.start_year + i\n",
    "        df = cluster.predictions[['predicted_label', '.geo']].copy()\n",
    "\n",
    "        # Rename prediction column to the year\n",
    "        df = df.rename(columns={'predicted_label': str(year)})\n",
    "\n",
    "        # Add to our list of yearly prediction DataFrames\n",
    "        all_year_dfs.append(df[[str(year)]])\n",
    "\n",
    "        # Combine geo info for this cluster\n",
    "        all_geos = all_geos.combine_first(df['.geo'])\n",
    "\n",
    "    # Outer join on index to merge all yearly predictions\n",
    "    merged = pd.concat(all_year_dfs, axis=1)\n",
    "\n",
    "    # Add the unified .geo column\n",
    "    merged['.geo'] = all_geos\n",
    "\n",
    "    return merged\n",
    "    # for cluster in clusterer.cluster_list:\n",
    "    #     predictions = cluster.create_predictions() \n",
    "    #     predictions.append(cluster.predictions['labels'].values)\n",
    "    \n",
    "    # return pd.DataFrame(predictions)\n",
    "\n",
    "merged = collect_predictions_by_year(clusterer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save merged predictions\n",
    "# merged.to_csv(\"product/gen_cluster900_15/merged_predictions_15_900.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e436d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv(\"product/gen_cluster900_15/merged_predictions_15_900.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a49649",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aa5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_geom = gpd.GeoDataFrame(geometry=boundary, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5613e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to region \n",
    "import utils as ut\n",
    "\n",
    "gdf_in, gdf_out = ut.clip_to_polygon(boundary_geom, merged)\n",
    "print(len(gdf_in), len(gdf_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9b2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_in.drop(columns=['file_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2cccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates based on index\n",
    "gdf_in = gdf_in.drop_duplicates(subset=['.geo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbe239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_totals_per_year = gdf_in.iloc[:, :6].apply(pd.Series.value_counts)\n",
    "class_totals_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_totals_per_year = class_totals_per_year.sort_index()\n",
    "\n",
    "# Transpose: years on x-axis, classes as lines\n",
    "class_totals_per_year.T.plot(kind='line', marker='o', figsize=(10, 6))\n",
    "\n",
    "plt.title(\"Land Cover Class Changes Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Tiles\")\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d4d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of land use per year (totals of unique land use classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc22c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd42eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "years = merged.columns[:-1]  \n",
    "\n",
    "# plot totals \n",
    "for year in years:\n",
    "    plt.plot(gdf_in[year].value_counts().index, merged[year].value_counts().values, label=year)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Predicted Labels Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "years = gdf_in.columns[:-1]  \n",
    "\n",
    "# plot totals \n",
    "for year in years:\n",
    "    plt.plot(gdf_in[year].value_counts().index, gdf_in[year].value_counts().values, label=year)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Predicted Labels Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "years = gdf_in.columns[:-1]  \n",
    "\n",
    "proportions = {}\n",
    "for year in years:\n",
    "    year_counts = gdf_in[year].value_counts(normalize=True)\n",
    "    proportions[year] = year_counts\n",
    "\n",
    "proportion_df = pd.DataFrame(proportions).fillna(0)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for label in proportion_df.index:\n",
    "    plt.plot(proportion_df.columns, proportion_df.loc[label], marker='o', label=label)\n",
    "\n",
    "plt.title('Proportion of Classes')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Class', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be82135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# years = gdf_in.columns[:-1]  \n",
    "\n",
    "# proportions = {}\n",
    "# for year in years:\n",
    "#     year_counts = gdf_in[year].value_counts(normalize=True)\n",
    "#     proportions[year] = year_counts\n",
    "\n",
    "# proportion_df = pd.DataFrame(proportions).fillna(0)\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# for label in proportion_df.index:\n",
    "#     plt.plot(proportion_df.columns, proportion_df.loc[label], marker='o', label=label)\n",
    "\n",
    "# plt.title('Proportion of Classes')\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('Proportion')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(title='Class', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 \n",
    "data_2019 = clusterer.cluster_list[0].data\n",
    "labels_2019 = clusterer.cluster_list[0].predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_2019\n",
    "urban_ids = labels_2019[labels_2019['predicted_label'] == \"Urban\"].index\n",
    "urban_data_2019 = data_2019.loc[data_2019.index.isin(urban_ids)]\n",
    "urban_data_2019_summary = ut.summarise(urban_data_2019)\n",
    "ut.create_figs(urban_data_2019_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f6259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agriculture \n",
    "agriculture_ids = labels_2019[labels_2019['predicted_label'] == \"Agricultural\"].index\n",
    "agriculture_data_2019 = data_2019.loc[data_2019.index.isin(agriculture_ids)]\n",
    "agriculture_data_2019_summary = ut.summarise(agriculture_data_2019)\n",
    "ut.create_figs(agriculture_data_2019_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ffe389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urban_vs_agriculture = agriculture_data_2019_summary - urban_data_2019_summary \n",
    "urban_vs_agriculture = urban_data_2019_summary - agriculture_data_2019_summary\n",
    "urban_vs_agriculture = urban_vs_agriculture.abs()\n",
    "ut.create_figs(urban_vs_agriculture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27655079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urban_vs_agriculture = agriculture_data_2019_summary - urban_data_2019_summary \n",
    "urban_vs_agriculture = agriculture_data_2019_summary - urban_data_2019_summary \n",
    "ut.create_figs(urban_vs_agriculture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_values = data_2019.copy()\n",
    "backgorund_summary = ut.summarise(background_values)\n",
    "ut.create_figs(backgorund_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_in_2019, gdf_out_2019 = ut.clip_to_polygon(boundary_geom, data_2019.copy())\n",
    "print(len(gdf_in_2019), len(gdf_out_2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124931c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_values = gdf_in_2019.copy()\n",
    "backgorund_summary = ut.summarise(background_values)\n",
    "ut.create_figs(backgorund_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
